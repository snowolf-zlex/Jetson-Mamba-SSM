#!/usr/bin/env python3
"""
Mamba-SSM å®‰è£…æ£€æŸ¥è„šæœ¬
å…¨é¢æ£€æŸ¥ Mamba åœ¨ Jetson ä¸Šçš„ç¼–è¯‘å®‰è£…çŠ¶æ€
"""
import os
import sys
import subprocess
import traceback
from pathlib import Path

# é¢œè‰²è¾“å‡º
class Colors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

def get_project_root():
    """è·å–é¡¹ç›®æ ¹ç›®å½•"""
    script_dir = Path(__file__).parent
    return script_dir.parent

def print_header(title):
    print(f"\n{Colors.HEADER}{Colors.BOLD}{'='*70}{Colors.ENDC}")
    print(f"{Colors.HEADER}{Colors.BOLD}{title:^70}{Colors.ENDC}")
    print(f"{Colors.HEADER}{Colors.BOLD}{'='*70}{Colors.ENDC}\n")

def print_section(title):
    print(f"\n{Colors.OKCYAN}{Colors.BOLD}â”â”â” {title} â”â”â”{Colors.ENDC}\n")

def print_ok(msg):
    print(f"{Colors.OKGREEN}âœ“ {msg}{Colors.ENDC}")

def print_fail(msg):
    print(f"{Colors.FAIL}âœ— {msg}{Colors.ENDC}")

def print_warning(msg):
    print(f"{Colors.WARNING}âš  {msg}{Colors.ENDC}")

def print_info(msg):
    print(f"  {msg}")

def get_system_info():
    """è·å–ç³»ç»Ÿä¿¡æ¯"""
    print_section("1. ç³»ç»Ÿç¯å¢ƒæ£€æŸ¥")

    # Python ç‰ˆæœ¬
    python_version = sys.version_info
    print_info(f"Python ç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")
    if python_version >= (3, 9):
        print_ok(f"Python ç‰ˆæœ¬ç¬¦åˆè¦æ±‚ (>= 3.9)")
    else:
        print_fail(f"Python ç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦ 3.9+ï¼Œå½“å‰ {python_version.major}.{python_version.minor}")

    # æ¶æ„
    import platform
    arch = platform.machine()
    print_info(f"ç³»ç»Ÿæ¶æ„: {arch}")
    if arch in ['aarch64', 'arm64']:
        print_ok(f"ARM64 æ¶æ„ (Jetson)")
    elif arch in ['x86_64', 'AMD64']:
        print_warning(f"x86_64 æ¶æ„ (å¯ç›´æ¥ä½¿ç”¨é¢„ç¼–è¯‘ wheel)")
    else:
        print_warning(f"æœªçŸ¥æ¶æ„: {arch}")

    # PyTorch
    try:
        import torch
        print_info(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
        print_info(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print_info(f"CUDA ç‰ˆæœ¬: {torch.version.cuda}")
            print_info(f"GPU æ•°é‡: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                print_info(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
            print_ok(f"CUDA ç¯å¢ƒæ­£å¸¸")
        else:
            print_warning(f"CUDA ä¸å¯ç”¨")
    except ImportError:
        print_fail(f"PyTorch æœªå®‰è£…")

def check_cuda_extensions():
    """æ£€æŸ¥ CUDA æ‰©å±•æ¨¡å—"""
    print_section("2. CUDA æ‰©å±•æ¨¡å—æ£€æŸ¥")

    project_root = get_project_root()
    src_dir = project_root / 'src'

    # selective_scan_cuda shim
    print_info("æ£€æŸ¥ selective_scan_cuda shim...")
    try:
        # æ·»åŠ é¡¹ç›®è·¯å¾„
        if str(src_dir) not in sys.path:
            sys.path.insert(0, str(src_dir))

        import selective_scan_cuda
        print_ok(f"selective_scan_cuda shim å¯¼å…¥æˆåŠŸ")
        print_info(f"  å¯ç”¨å‡½æ•°: {selective_scan_cuda.__all__}")

        # æ£€æŸ¥å‡½æ•°æ˜¯å¦å¯è°ƒç”¨
        if callable(selective_scan_cuda.fwd):
            print_ok(f"  fwd å‡½æ•°å¯è°ƒç”¨")
        else:
            print_fail(f"  fwd å‡½æ•°ä¸å¯è°ƒç”¨")

        if callable(selective_scan_cuda.bwd):
            print_ok(f"  bwd å‡½æ•°å¯è°ƒç”¨")
        else:
            print_fail(f"  bwd å‡½æ•°ä¸å¯è°ƒç”¨")

    except ImportError as e:
        print_fail(f"selective_scan_cuda shim å¯¼å…¥å¤±è´¥: {e}")

    # selective_scan_cuda_core
    print_info("\næ£€æŸ¥ selective_scan_cuda_core (æ ¸å¿ƒ CUDA æ‰©å±•)...")
    try:
        import selective_scan_cuda_core
        print_ok(f"selective_scan_cuda_core å¯¼å…¥æˆåŠŸ")

        # æ£€æŸ¥ fwd/bwd å‡½æ•°
        if hasattr(selective_scan_cuda_core, 'fwd'):
            print_ok(f"  fwd å‡½æ•°å­˜åœ¨")
        if hasattr(selective_scan_cuda_core, 'bwd'):
            print_ok(f"  bwd å‡½æ•°å­˜åœ¨")

    except ImportError as e:
        print_fail(f"selective_scan_cuda_core å¯¼å…¥å¤±è´¥: {e}")
        print_info(f"  è¿™æ„å‘³ç€ Mamba CUDA æ‰©å±•æœªæ­£ç¡®ç¼–è¯‘å®‰è£…")

    # mamba_ssm
    print_info("\næ£€æŸ¥ mamba_ssm åŒ…...")
    try:
        import mamba_ssm
        print_ok(f"mamba_ssm åŒ…å¯¼å…¥æˆåŠŸ")
        print_info(f"  ç‰ˆæœ¬: {getattr(mamba_ssm, '__version__', 'unknown')}")
        print_info(f"  è·¯å¾„: {mamba_ssm.__file__}")
    except ImportError as e:
        print_fail(f"mamba_ssm åŒ…å¯¼å…¥å¤±è´¥: {e}")

def check_mamba_modules():
    """æ£€æŸ¥ Mamba æ ¸å¿ƒæ¨¡å—"""
    print_section("3. Mamba æ ¸å¿ƒæ¨¡å—æ£€æŸ¥")

    # Mamba æ¨¡å—
    print_info("æ£€æŸ¥ Mamba æ¨¡å—...")
    try:
        from mamba_ssm import Mamba
        print_ok(f"Mamba ç±»å¯¼å…¥æˆåŠŸ")

        # åˆ›å»ºå®ä¾‹æµ‹è¯•
        import torch
        device = "cuda" if torch.cuda.is_available() else "cpu"

        mamba = Mamba(
            d_model=16,
            d_state=8,
            d_conv=4,
            expand=2,
        ).to(device)
        print_ok(f"Mamba å®ä¾‹åˆ›å»ºæˆåŠŸ (d_model=16)")

        # å‰å‘ä¼ æ’­æµ‹è¯•
        x = torch.randn(1, 10, 16).to(device)
        with torch.no_grad():
            y = mamba(x)
        print_ok(f"Mamba å‰å‘ä¼ æ’­æˆåŠŸ: {x.shape} -> {y.shape}")

    except ImportError as e:
        print_fail(f"Mamba å¯¼å…¥å¤±è´¥: {e}")
    except Exception as e:
        print_fail(f"Mamba æµ‹è¯•å¤±è´¥: {e}")

    # Mamba2 æ¨¡å—
    print_info("\næ£€æŸ¥ Mamba2 æ¨¡å—...")
    try:
        from mamba_ssm import Mamba2
        print_ok(f"Mamba2 ç±»å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print_warning(f"Mamba2 å¯¼å…¥å¤±è´¥ (å¯é€‰): {e}")

def check_yolo_mamba():
    """æ£€æŸ¥ YOLO Mamba é›†æˆ"""
    print_section("4. YOLO Mamba é›†æˆæ£€æŸ¥")

    project_root = get_project_root()
    yolo_dir = project_root / 'src' / 'yolo'

    print_info("æ£€æŸ¥ mamba_yolo æ¨¡å—...")
    try:
        if str(yolo_dir) not in sys.path:
            sys.path.insert(0, str(yolo_dir))

        from mamba_yolo import SS2D, VSSBlock_YOLO, XSSBlock, CrossScan, CrossMerge
        print_ok(f"mamba_yolo å¯¼å…¥æˆåŠŸ")
        print_info(f"  å¯ç”¨ç±»: SS2D, VSSBlock_YOLO, XSSBlock, CrossScan, CrossMerge")

        # æµ‹è¯• SS2D
        import torch
        device = "cuda" if torch.cuda.is_available() else "cpu"

        print_info("\n  æµ‹è¯• SS2D æ¨¡å—...")
        ss2d = SS2D(d_model=16, d_state=8, ssm_ratio=2.0, d_conv=3)
        x = torch.randn(1, 16, 8, 8).to(device)

        try:
            with torch.no_grad():
                y = ss2d(x)
            print_ok(f"    SS2D å‰å‘ä¼ æ’­æˆåŠŸ: {x.shape} -> {y.shape}")
        except NameError as e:
            if 'selective_scan_cuda_core' in str(e):
                print_fail(f"    SS2D éœ€è¦ selective_scan_cuda_core (æœªç¼–è¯‘)")
            else:
                raise
        except Exception as e:
            print_fail(f"    SS2D å‰å‘ä¼ æ’­å¤±è´¥: {e}")

    except ImportError as e:
        print_fail(f"mamba_yolo å¯¼å…¥å¤±è´¥: {e}")

def check_causal_conv1d():
    """æ£€æŸ¥ causal_conv1d"""
    print_section("5. causal_conv1d ä¾èµ–æ£€æŸ¥")

    print_info("æ£€æŸ¥ causal_conv1d...")
    try:
        import causal_conv1d
        print_ok(f"causal_conv1d å¯¼å…¥æˆåŠŸ")
        print_info(f"  ç‰ˆæœ¬: {getattr(causal_conv1d, '__version__', 'unknown')}")

        from causal_conv1d import causal_conv1d_fn, causal_conv1d_update
        print_ok(f"  causal_conv1d_fn å¯ç”¨")
        print_ok(f"  causal_conv1d_update å¯ç”¨")

    except ImportError as e:
        print_fail(f"causal_conv1d å¯¼å…¥å¤±è´¥: {e}")
        print_info(f"  å®‰è£…æ–¹æ³•: pip install causal-conv1d")
        print_info(f"  æˆ–ä½¿ç”¨é¢„ç¼–è¯‘ wheel: pip install wheels/causal_conv1d-*.whl")

def check_installed_files():
    """æ£€æŸ¥å·²å®‰è£…çš„æ–‡ä»¶"""
    print_section("6. å·²å®‰è£…æ–‡ä»¶æ£€æŸ¥")

    try:
        import mamba_ssm
        mamba_path = Path(mamba_ssm.__file__).parent

        print_info(f"mamba_ssm è·¯å¾„: {mamba_path}")

        # æŸ¥æ‰¾ .so æ–‡ä»¶
        so_files = list(mamba_path.glob("**/*.so"))
        if so_files:
            print_ok(f"æ‰¾åˆ° {len(so_files)} ä¸ªç¼–è¯‘çš„ .so æ–‡ä»¶:")
            for f in so_files:
                print_info(f"  - {f.name}")
        else:
            print_warning(f"æœªæ‰¾åˆ° .so æ–‡ä»¶ (å¯èƒ½æœªç¼–è¯‘æˆ–å®‰è£…ä¸å®Œæ•´)")

        # æ£€æŸ¥ ops ç›®å½•
        ops_path = mamba_path / "ops"
        if ops_path.exists():
            print_info(f"\nops ç›®å½•å†…å®¹:")
            for item in ops_path.iterdir():
                if item.is_file():
                    print_info(f"  - {item.name}")
    except ImportError:
        print_fail(f"mamba_ssm æœªå®‰è£…ï¼Œæ— æ³•æ£€æŸ¥æ–‡ä»¶")

def run_performance_test():
    """è¿è¡Œç®€å•æ€§èƒ½æµ‹è¯•"""
    print_section("7. æ€§èƒ½æµ‹è¯• (å¯é€‰)")

    try:
        import torch
    except ImportError:
        print_warning("PyTorch æœªå®‰è£…ï¼Œè·³è¿‡æ€§èƒ½æµ‹è¯•")
        return

    if not torch.cuda.is_available():
        print_warning("CUDA ä¸å¯ç”¨ï¼Œè·³è¿‡æ€§èƒ½æµ‹è¯•")
        return

    print_info("è¿è¡Œ Mamba æ€§èƒ½åŸºå‡†æµ‹è¯•...")

    try:
        from mamba_ssm import Mamba
        import time

        device = "cuda"
        batch_size = 4
        seq_len = 512
        d_model = 64

        # åˆ›å»ºæ¨¡å‹
        model = Mamba(
            d_model=d_model,
            d_state=16,
            d_conv=4,
            expand=2,
        ).to(device)
        model.eval()

        # é¢„çƒ­
        x = torch.randn(batch_size, seq_len, d_model, device=device)
        with torch.no_grad():
            for _ in range(3):
                _ = model(x)

        # æµ‹è¯•
        torch.cuda.synchronize()
        start = time.time()
        iterations = 100

        with torch.no_grad():
            for _ in range(iterations):
                _ = model(x)

        torch.cuda.synchronize()
        elapsed = time.time() - start

        throughput = (batch_size * iterations) / elapsed
        latency = (elapsed / iterations) * 1000

        print_ok(f"æ€§èƒ½æµ‹è¯•å®Œæˆ:")
        print_info(f"  è¾“å…¥å½¢çŠ¶: ({batch_size}, {seq_len}, {d_model})")
        print_info(f"  è¿­ä»£æ¬¡æ•°: {iterations}")
        print_info(f"  æ€»è€—æ—¶: {elapsed:.3f}s")
        print_info(f"  ååé‡: {throughput:.1f} samples/s")
        print_info(f"  å»¶è¿Ÿ: {latency:.2f} ms")

    except Exception as e:
        print_fail(f"æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")

def print_summary(results):
    """æ‰“å°æµ‹è¯•æ€»ç»“"""
    print_section("æµ‹è¯•æ€»ç»“")

    total = len(results)
    passed = sum(results.values())

    print(f"\n{'æµ‹è¯•é¡¹':<40} {'ç»“æœ':>10}")
    print(f"{'-'*60}")

    for name, result in results.items():
        status = f"{Colors.OKGREEN}âœ“ é€šè¿‡{Colors.ENDC}" if result else f"{Colors.FAIL}âœ— å¤±è´¥{Colors.ENDC}"
        print(f"{name:<40} {status:>15}")

    print(f"{'-'*60}")
    print(f"\næ€»è®¡: {passed}/{total} é¡¹é€šè¿‡")

    if passed == total:
        print(f"\n{Colors.OKGREEN}{Colors.BOLD}ğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼Mamba-SSM å®‰è£…æ­£ç¡®ã€‚{Colors.ENDC}")
        return 0
    else:
        print(f"\n{Colors.WARNING}{Colors.BOLD}âš  æœ‰ {total - passed} é¡¹æ£€æŸ¥å¤±è´¥{Colors.ENDC}")
        print(f"\nå»ºè®®:")
        project_root = get_project_root()
        if not results.get("CUDA æ‰©å±•"):
            print(f"  - ä½¿ç”¨é¢„ç¼–è¯‘ wheel:")
            print(f"    pip install {project_root}/wheels/mamba_ssm-*.whl")
        if not results.get("causal_conv1d"):
            print(f"  - å®‰è£… causal_conv1d:")
            print(f"    pip install {project_root}/wheels/causal_conv1d-*.whl")
        if not results.get("YOLO Mamba"):
            print(f"  - è¿è¡Œè¡¥ä¸åº”ç”¨è„šæœ¬:")
            print(f"    python {project_root}/scripts/apply_patches.py")
        return 1

def main():
    print_header("Mamba-SSM Jetson å®‰è£…æ£€æŸ¥")

    results = {}

    # è¿è¡Œå„é¡¹æ£€æŸ¥
    try:
        get_system_info()
    except Exception as e:
        print_fail(f"ç³»ç»Ÿä¿¡æ¯æ£€æŸ¥å‡ºé”™: {e}")

    try:
        check_cuda_extensions()
        # ç®€å•åˆ¤æ–­æ˜¯å¦æœ‰æ ¸å¿ƒæ‰©å±•
        try:
            import selective_scan_cuda_core
            results["CUDA æ‰©å±•"] = True
        except:
            results["CUDA æ‰©å±•"] = False
    except Exception as e:
        print_fail(f"CUDA æ‰©å±•æ£€æŸ¥å‡ºé”™: {e}")
        results["CUDA æ‰©å±•"] = False

    try:
        check_mamba_modules()
        try:
            from mamba_ssm import Mamba
            results["Mamba æ¨¡å—"] = True
        except:
            results["Mamba æ¨¡å—"] = False
    except Exception as e:
        print_fail(f"Mamba æ¨¡å—æ£€æŸ¥å‡ºé”™: {e}")
        results["Mamba æ¨¡å—"] = False

    try:
        check_yolo_mamba()
        try:
            project_root = get_project_root()
            yolo_dir = project_root / 'src' / 'yolo'
            sys.path.insert(0, str(yolo_dir))
            from mamba_yolo import SS2D
            import torch
            # ç®€å•æµ‹è¯•
            ss2d = SS2D(d_model=16)
            x = torch.randn(1, 16, 4, 4)
            try:
                y = ss2d(x)
                results["YOLO Mamba"] = True
            except NameError:
                results["YOLO Mamba"] = False
        except:
            results["YOLO Mamba"] = False
    except Exception as e:
        print_fail(f"YOLO Mamba æ£€æŸ¥å‡ºé”™: {e}")
        results["YOLO Mamba"] = False

    try:
        check_causal_conv1d()
        try:
            import causal_conv1d
            results["causal_conv1d"] = True
        except:
            results["causal_conv1d"] = False
    except Exception as e:
        print_fail(f"causal_conv1d æ£€æŸ¥å‡ºé”™: {e}")
        results["causal_conv1d"] = False

    try:
        check_installed_files()
    except Exception as e:
        print_fail(f"æ–‡ä»¶æ£€æŸ¥å‡ºé”™: {e}")

    try:
        run_performance_test()
    except Exception as e:
        print_fail(f"æ€§èƒ½æµ‹è¯•å‡ºé”™: {e}")

    # æ‰“å°æ€»ç»“
    return print_summary(results)

if __name__ == "__main__":
    sys.exit(main())
